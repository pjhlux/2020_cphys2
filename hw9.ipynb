{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "### MNIST 패션 이미지를 CNN을 이용하여 분류하세요. CNN을 이용한 분류 결과를 MLP와 비교해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import models \n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "# preprocessing\n",
    "X_train = X_train.reshape((60000, 28*28))\n",
    "X_train = X_train/255\n",
    "\n",
    "X_test = X_test.reshape((10000, 28*28))\n",
    "X_test = X_test/255\n",
    "\n",
    "net = models.Sequential()\n",
    "net.add(layers.Dense(512, activation='relu', input_shape=(28*28,))) \n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dropout(0.5))\n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dropout(0.5))\n",
    "net.add(layers.Dense(10, activation='softmax')) \n",
    "net.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5625 - acc: 0.8003 - val_loss: 0.4534 - val_acc: 0.8237\n",
      "Epoch 2/8\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.3968 - acc: 0.8565 - val_loss: 0.4383 - val_acc: 0.8354\n",
      "Epoch 3/8\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.3553 - acc: 0.8711 - val_loss: 0.3737 - val_acc: 0.8692\n",
      "Epoch 4/8\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3329 - acc: 0.8784 - val_loss: 0.3369 - val_acc: 0.8816\n",
      "Epoch 5/8\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3132 - acc: 0.8860 - val_loss: 0.3653 - val_acc: 0.8645\n",
      "Epoch 6/8\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3019 - acc: 0.8896 - val_loss: 0.3351 - val_acc: 0.8742\n",
      "Epoch 7/8\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.2920 - acc: 0.8944 - val_loss: 0.3233 - val_acc: 0.8797\n",
      "Epoch 8/8\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.2821 - acc: 0.8968 - val_loss: 0.3312 - val_acc: 0.8786\n"
     ]
    }
   ],
   "source": [
    "val= net.fit(partial_X_train,partial_y_train,epochs=8, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3678 - acc: 0.8692\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP 분류정확도 0.8692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "# preprocessing\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_train = X_train/255\n",
    "\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "cnn.add(layers.MaxPooling2D((2,2)))\n",
    "cnn.add(layers.Conv2D(64,(3,3), activation='relu')) \n",
    "cnn.add(layers.MaxPooling2D((2,2)))\n",
    "cnn.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(512, activation='relu')) \n",
    "cnn.add(layers.Dropout(0.5)) \n",
    "cnn.add(layers.Dense(64, activation='relu')) \n",
    "cnn.add(layers.Dense(10, activation='softmax')) \n",
    "cnn.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.5264 - acc: 0.8047 - val_loss: 0.3420 - val_acc: 0.8752\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.3266 - acc: 0.8815 - val_loss: 0.3249 - val_acc: 0.8849\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.2829 - acc: 0.8965 - val_loss: 0.2683 - val_acc: 0.8991\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.2547 - acc: 0.9066 - val_loss: 0.2687 - val_acc: 0.9029\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2322 - acc: 0.9143 - val_loss: 0.2452 - val_acc: 0.9085\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.2106 - acc: 0.9215 - val_loss: 0.2560 - val_acc: 0.9082\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1951 - acc: 0.9275 - val_loss: 0.2408 - val_acc: 0.9089\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1801 - acc: 0.9336 - val_loss: 0.2551 - val_acc: 0.9058\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1698 - acc: 0.9374 - val_loss: 0.2469 - val_acc: 0.9123\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1564 - acc: 0.9410 - val_loss: 0.2703 - val_acc: 0.9088\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1473 - acc: 0.9442 - val_loss: 0.2674 - val_acc: 0.9128\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1385 - acc: 0.9487 - val_loss: 0.2644 - val_acc: 0.9155\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.1301 - acc: 0.9521 - val_loss: 0.2926 - val_acc: 0.9105\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.1246 - acc: 0.9538 - val_loss: 0.2843 - val_acc: 0.9143\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1170 - acc: 0.9559 - val_loss: 0.2971 - val_acc: 0.9131\n"
     ]
    }
   ],
   "source": [
    "val= cnn.fit(partial_X_train, partial_y_train, epochs=15, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3159 - acc: 0.9141\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN 분류정확도 0.9141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## MLP vs CNN\n",
    "### 86.92 % : 91.41 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
